{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "This notebook contains the code written to scrape Metacritic for game details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send request. I'm not sure why I need this header, but it doesn't work without it.\n",
    "meta = requests.get(url, headers = user_agent)\n",
    "meta = BeautifulSoup(meta.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is required otherwise the request won't work\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "urls = []\n",
    "names = []\n",
    "# Metacritic starts index at 0. There are currently 192 pages of games, and this is easier than pulling that informtaion thru scraping.\n",
    "num_pages = 191\n",
    "for page in range(0, num_pages):\n",
    "    url = f\"https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?view=condensed&page={page}\"\n",
    "    meta = requests.get(url, headers = user_agent)\n",
    "    meta = BeautifulSoup(meta.text)\n",
    "    # These classes contain the games. Four chunks of information separated by ads..\n",
    "    games = meta.find_all(\"div\", {\"class\": [\"browse_list_wrapper one browse-list-large\", \"browse_list_wrapper two browse-list-large\", \"browse_list_wrapper three browse-list-large\", \"browse_list_wrapper four browse-list-large\"]})\n",
    "\n",
    "    for i in range(4):\n",
    "        name = games[i].find_all(\"h3\")\n",
    "        names = names + name\n",
    "\n",
    "        # Extract just the url\n",
    "        url = games[i].find_all(\"a\", {\"class\" : \"title\"}, href = True)\n",
    "        for a in url:\n",
    "            urls.append(a[\"href\"])\n",
    "    time.sleep(0.5)\n",
    "# Change to string objects, remove html tage\n",
    "names = [name.text for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <h3> was used as tag for game name and 'User Score', so we need to remove elements that are user score.\n",
    "# This gives an error, because when it pops the length of the list is reduced. The task is done by the time it fails though, so it doesn't really matter. Use except clause to end gracefully\n",
    "\n",
    "for i in range(len(names) - 1):\n",
    "    try:\n",
    "        if(names[i] == 'User Score'):\n",
    "            names.pop(i)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = pd.DataFrame(list(zip(names, urls)), columns = [\"Name\", \"URL\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#games_df.to_csv(r'allgames.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
